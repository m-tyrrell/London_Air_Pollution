modelstring = "model {
for (i in 1:n) {
y[i] ~ dnorm(mu[z[i]], tau[i])
z[i] ~ dcat(group_probs)
}
group_probs ~ ddirich(d)
for (j in 1:ngroups) {
mu_raw[j] ~ dnorm(0, 1E-6)
#        tau[j] ~ dgamma(0.001, 0.001)
#       sd[j] = 1/sqrt(tau[j])
d[j] = 2
}
tau ~ dgamma(0.001, 0.001)
mu = sort(mu_raw) # Avoids label switching issues
}"
ngroups = 2
jags_data = list(y=y, n=length(y2), ngroups=ngroups)
model = jags.model(textConnection(modelstring), data=jags_data,n.chains=4)
update(model,n.iter=1E4)
modelstring = "model {
for (i in 1:n) {
y[i] ~ dnorm(mu[z[i]], tau)
z[i] ~ dcat(group_probs)
}
group_probs ~ ddirich(d)
for (j in 1:ngroups) {
mu_raw[j] ~ dnorm(0, 1E-6)
#        tau[j] ~ dgamma(0.001, 0.001)
#       sd[j] = 1/sqrt(tau[j])
d[j] = 2
}
tau ~ dgamma(0.001, 0.001)
mu = sort(mu_raw) # Avoids label switching issues
}"
y2 = y/sd(y)
ngroups = 2
jags_data = list(y=y2, n=length(y2), ngroups=ngroups)
model = jags.model(textConnection(modelstring), data=jags_data,n.chains=4)
update(model,n.iter=1E4)
samples = coda.samples(model=model, variable.names=c("mu","group_probs"), n.iter=1E4, thin=6)
mcmc_mat = as.matrix(samples[[1]])
post_p = dim(summary(samples)[[1]])[1]
par(mfrow=c(2,3))
for (i in 1:post_p) {
acf(mcmc_mat[,i], lag.max=60, main=colnames(mcmc_mat)[i]) }
summary(samples)
hist(y2, breaks=200)
y2 = c(scale(y))
ngroups = 2
jags_data = list(y=y2, n=length(y2), ngroups=ngroups)
model = jags.model(textConnection(modelstring), data=jags_data,n.chains=4)
update(model,n.iter=1E4)
samples = coda.samples(model=model, variable.names=c("mu","group_probs"), n.iter=1E4)
summary(samples)
hist(y2, breaks=200)
#Autocorrelation plots
mcmc_mat = as.matrix(samples[[1]])
post_p = dim(summary(samples)[[1]])[1]
par(mfrow=c(2,3))
for (i in 1:post_p) {
acf(mcmc_mat[,i], lag.max=60, main=colnames(mcmc_mat)[i]) }
model = jags.model(textConnection(modelstring), data=jags_data,n.chains=4)
update(model,n.iter=1E4)
samples = coda.samples(model=model, variable.names=c("mu","group_probs"), n.iter=1E4*10, thin=10)
#Autocorrelation plots
mcmc_mat = as.matrix(samples[[1]])
post_p = dim(summary(samples)[[1]])[1]
par(mfrow=c(2,3))
for (i in 1:post_p) {
acf(mcmc_mat[,i], lag.max=60, main=colnames(mcmc_mat)[i]) }
# Effective Sample Size
effectiveSize(samples)
# Gelman Ruben - 1 is good. Values bigger than 1.2 should worry
gelman.diag(samples, multivariate = FALSE)
summary(samples)
ngroups = 3
jags_data = list(y=y2, n=length(y2), ngroups=ngroups)
model = jags.model(textConnection(modelstring), data=jags_data,n.chains=4)
update(model,n.iter=1E4)
samples = coda.samples(model=model, variable.names=c("mu","group_probs"), n.iter=1E4)
summary(samples)
hist(y2, breaks=200)
library(rjags)
library(ggplot2)
summary_table(samples)
summary_table = function(samples){
# Unstandardize y parameters
params = as.data.frame(summary(samples)[[1]])
# Convert 95% HDI to df
HPD = as.data.frame(HPDinterval(samples[[1]]))
# Bind Parameters to HDI and unstandardize
params = cbind(params[,1], HPD)
names(params) = c("Posterior mean", "HDI lower", "HDI upper")
round(params,3)
}
summary_table(samples)
library(MASS)
data(SP500)
y = SP500
hist(y)
hist(y, breaks = 50)
y = SP500[1:500]
hist(y, breaks = 50)
y2 = y[2:500]-y[1:499]
plot(y,y2)
y1 = y[2:500]
y2 = y1-y[1:499]
plot(y1,y2)
yt = y[2:500]
ytminus1 = yt-y[1:499]
plot(yt, ytminus1)
plot(ytminus1, yt)
mod_str = "model {
# Initial hidden state
p0[1] = r
p0[2] = 1-r
x[1] ~ dcat(p0)
# Other hidden states
q[1,1] = q11
q[1,2] = 1 - q11
q[2,1] = 1 - q22
q[2,2] = q22
for (i in 2:n) {
x[i] ~ dcat(q[x[i-1],])
}
# Observations
for (i in 1:n) {
y[i] ~ dnorm(mu[x[i]], tau[x[i]])
}
# Priors
for (j in 1:2) {
mu_raw[j] ~ dnorm(0, 1E-6)
tau[j] ~ dgamma(0.001, 0.001)
}
mu = sort(mu_raw)
r ~ dunif(0, 1)
q11 ~ dunif(0, 1)
q22 ~ dunif(0, 1)
}"
jags_data = list(y=y, n=length(waiting))
model = jags.model(textConnection(mod_str), data=jags_data, n.chains=4)
update(model, n.iter=1E3)
samples = coda.samples(model=model, variable.names=c("mu", "tau", "r", "q11", "q22"), n.iter=1E3)
jags_data = list(y=y, n=length(y))
model = jags.model(textConnection(mod_str), data=jags_data, n.chains=4)
update(model, n.iter=1E3)
samples = coda.samples(model=model, variable.names=c("mu", "tau", "r", "q11", "q22"), n.iter=1E3)
mcmc_mat = as.matrix(samples[[1]])
post_p = dim(summary(samples)[[1]])[1]
par(mfrow=c(3,3))
for (i in 1:post_p) {
acf(mcmc_mat[,i], lag.max=150, main=colnames(mcmc_mat)[i])
}
#Autocorrelation plots
mcmc_mat = as.matrix(samples[[1]])
post_p = dim(summary(samples)[[1]])[1]
par(mfrow=c(3,3))
for (i in 1:post_p) {
acf(mcmc_mat[,i], lag.max=150, main=colnames(mcmc_mat)[i])
for (i in 1:post_p) {
acf(mcmc_mat[,i], lag.max=150, main=colnames(mcmc_mat)[i])
}
)
#Autocorrelation plots
mcmc_mat = as.matrix(samples[[1]])
post_p = dim(summary(samples)[[1]])[1]
par(mfrow=c(3,3))
for (i in 1:post_p) {
acf(mcmc_mat[,i], lag.max=150, main=colnames(mcmc_mat)[i])
}
jags_data = list(y=y, n=length(y))
model = jags.model(textConnection(mod_str), data=jags_data, n.chains=4)
update(model, n.iter=1E4)
samples = coda.samples(model=model, variable.names=c("mu", "tau", "r", "q11", "q22"), n.iter=1E4)
#Autocorrelation plots
mcmc_mat = as.matrix(samples[[1]])
post_p = dim(summary(samples)[[1]])[1]
par(mfrow=c(3,3))
for (i in 1:post_p) {
acf(mcmc_mat[,i], lag.max=150, main=colnames(mcmc_mat)[i])
}
plot(samples, auto.layout=FALSE, ask=TRUE, density=FALSE)
plot(samples, auto.layout=FALSE, ask=TRUE, density=FALSE)
model = jags.model(textConnection(mod_str), data=jags_data, n.chains=4)
update(model, n.iter=1E5)
samples = coda.samples(model=model, variable.names=c("mu", "tau", "r", "q11", "q22"), n.iter=1E5, thin = 100)
mcmc_mat = as.matrix(samples[[1]])
post_p = dim(summary(samples)[[1]])[1]
par(mfrow=c(3,3))
for (i in 1:post_p) {
acf(mcmc_mat[,i], lag.max=150, main=colnames(mcmc_mat)[i])
}
# Effective Sample Size
effectiveSize(samples)
summary_table(samples)
summary(samples)
HDI(samples)
#Trace plots
par(mfrow=c(3,3))
plot(samples, auto.layout=FALSE, ask=TRUE, density=FALSE)
# Identify target files
file_names = list.files(path="data/site_peaks", pattern="*.rds")
library(dtwclust)
data(uciCT)
# Remove recalcitrant R object
rm(titanic_train)
View(CharTraj)
View(CharTrajMV)
require("TSclust")
proxy::pr_DB$set_entry(FUN = diss.ACF, names = c("ACFD"),
loop = TRUE, type = "metric", distance = TRUE,
description = "Autocorrelation-based distance")
proxy
pr_DB$get_entries()
# Partitional clustering
tsclust(CharTraj[1L:10L], k = 2L,
distance = "ACFD", seed = 838)
# Partitional clustering
tsclust(CharTraj[1L:10L], k = 2L,
distance = "nDTW", seed = 838)
# Normalized DTW
ndtw <- function(x, y, ...) {
dtw(x, y, ...,
step.pattern = asymmetric,
distance.only = TRUE)$normalizedDistance
}
# Register the distance with proxy
proxy::pr_DB$set_entry(FUN = ndtw, names = c("nDTW"),
loop = TRUE, type = "metric", distance = TRUE,
description = "Normalized, asymmetric DTW")
# Partitional clustering
tsclust(CharTraj[1L:10L], k = 2L,
distance = "nDTW", seed = 838)
# Partitional clustering
tsclust(CharTraj[1L:100L], k = 2L,
distance = "nDTW", seed = 838)
# Reinterpolate to same length
data <- reinterpolate(CharTraj, new.length = max(lengths(CharTraj)))
# Calculate the DTW distances between all elements
system.time(D1 <- proxy::dist(data[1L:5L], data[6L:100L],
method = "dtw_basic",
##    user  system elapsed
##   0.067   0.000   0.067
# Nearest neighbors
NN1 <- apply(D1, 1L, which.min)
# Calculate the distance matrix with dtw_lb
system.time(D2 <- dtw_lb(data[1L:5L], data[6L:100L],
window.size = 20L))
##    user  system elapsed
##   0.009   0.000   0.009
# Nearest neighbors
NN2 <- apply(D2, 1L, which.min) # Same results?
all(NN1 == NN2)
## [1] TRUE
# Reinterpolate to same length
data <- reinterpolate(CharTraj, new.length = max(lengths(CharTraj)))
# Calculate the DTW distances between all elements
system.time(D1 <- proxy::dist(data[1L:5L], data[6L:100L], method = "dtw_basic", window.size = 20L))
# Nearest neighbors
NN1 <- apply(D1, 1L, which.min)
# Calculate the distance matrix with dtw_lb
system.time(D2 <- dtw_lb(data[1L:5L], data[6L:100L],
window.size = 20L))
# Nearest neighbors
NN2 <- apply(D2, 1L, which.min)
# Same results?
all(NN1 == NN2)
View(data)
View(CharTraj)
D1
class(D1)
NN1
D2
plot(CharTraj[1])
CharTraj[1]
as.numeric(CharTraj[1])
unlist(CharTraj[1])
test = unlist(CharTraj[1])
plot(test)
test2 = unlist(CharTraj[2])
plot(test2)
plot(test)
test3 = unlist(CharTraj[3])
plot(test3)
plot(test2)
plot(test3)
test3 = unlist(CharTraj[26])
plot(test3)
plot(test2)
plot(test3)
###
# Exclude a series as an example
database <- data[-100L]
View(database)
# Return label of nearest neighbor
CharTrajLabels[which.min(d)]
classify_series <- function(query) {
d <- dtw_lb(database, query, window.size = 18L, nn.margin = 2L)
# Return label of nearest neighbor
CharTrajLabels[which.min(d)]
}
# 100-th series is a Z character
classify_series(data[100L])
hc_sbd <- tsclust(CharTraj, type = "h", k = 20L,
preproc = zscore, seed = 899,
distance = "sbd", centroid = shape_extraction,
control = hierarchical_control(method = "average"))
# By default, the dendrogram is plotted in hierarchical clustering
plot(hc_sbd)
plot(hc_sbd, type = "sc")
View(hc_sbd)
hc_sbd@clusinfo
class(hc_sbd@clusinfo)
library(dplyr)
arrange(hc_sbd@clusinfo, size)
hc_sbd <- tsclust(CharTraj, type = "h", k = 10,
preproc = zscore, seed = 899,
distance = "sbd", centroid = shape_extraction,
control = hierarchical_control(method = "average"))
# By default, the dendrogram is plotted in hierarchical clustering
plot(hc_sbd)
plot(hc_sbd, type = "sc")
hc_sbd@clusinfo
hc_sbd <- tsclust(CharTraj, type = "h", k = 20,
preproc = zscore, seed = 899,
distance = "sbd", centroid = shape_extraction,
control = hierarchical_control(method = "average"))
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 1L)
plot(hc_sbd, type = "centroids", clus = 1L)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 1L)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 2)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 3)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 4)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 5)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 6)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 7)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 8)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 9)
# Focusing on the first cluster
plot(hc_sbd, type = "series", clus = 10)
###
require("cluster")
tsclust(CharTraj[1L:20L], type = "h", k = 4L,
distance = "dtw_basic",
control = hierarchical_control(method = diana),
args = tsclust_args(dist = list(window.size = 18L)))
# Reinterpolate to same length
data <- reinterpolate(CharTraj, new.length = max(lengths(CharTraj)))
# z-normalization
data <- zscore(data[60L:100L])
pc_dtw <- tsclust(data, k = 4L,
distance = "dtw_basic", centroid = "dba",
trace = TRUE, seed = 8,
norm = "L2", window.size = 20L,
args = tsclust_args(cent = list(trace = TRUE)))
pc_dtwlb <- tsclust(data, k = 4L,
distance = "dtw_lb", centroid = "dba",
trace = TRUE, seed = 8,
norm = "L2", window.size = 20L,
control = partitional_control(pam.precompute = FALSE),
args = tsclust_args(cent = list(trace = TRUE)))
pc_ks <- tsclust(data, k = 4L,
distance = "sbd", centroid = "shape",
seed = 8, trace = TRUE)
pc_tp <- tsclust(data, k = 4L, type = "t",
seed = 8, trace = TRUE,
control = tadpole_control(dc = 1.5,
window.size = 20L))
sapply(list(DTW = pc_dtw, DTW_LB = pc_dtwlb, kShape = pc_ks, TADPole = pc_tp),
cvi, b = CharTrajLabels[60L:100L], type = "VI")
plot(pc_dtw)
plot(pc_dtwlb)
plot(pc_ks)
plot(pc_tp)
plot(pc_ks)
pc_ks@clusinfo
pc_ks@clusinfo
pc_ks@cldist
View(pc_ks)
View(pc_dtwlb)
View(pc_dtw)
View(pc_tp)
# Set working directory !! INPUT REQUIRED !!
wd = file.path('Desktop','DK_GST_MAY2019')
# Set data subfolder name !! INPUT REQUIRED !!
subfolder = 'data'
# Set file name !! INPUT REQUIRED !!
file_name = 'Pollution Health and Sociodemographic data.csv'
# Ensure the following packages are installed !! INPUT REQUIRED !!
library(reshape2)
library(plyr)
library(tidyverse)
library(stringr)
library(lubridate)
library(ggplot2)
library(dplyr)
# Set working directory
wd = file.path('Desktop','DS_Projects','DK_GST_MAY2019')
setwd(wd)
# Set file path to csv file
path = file.path(subfolder,file_name)
# Load file
pollution = read.csv(path)
# List of interesting variables (URBAN, DIVERSITY, DEPRIVATION)
col_names_filter = c("LSOA.Code","NOx","PM10","PM2.5",
"Population.aged.0.15","Population.aged.65.","Population.density..persons.per.hectare.",
"Change.in.population.2001.to.2017","Christian","People.with.no.religious.belief","Muslim",
"White.ethnic.groups","Black.ethnic.groups","Asian.ethnic.groups","Born.in.EU.Accession.countries",
"Born.in.non.European.countries","Main.language.is.English","Economically.inactive",
"People.with.no.qualifications","Index.of.Multiple.Deprivation..IMD..Score",
"Households.in.poverty","Net.annual.household.income.estimate.after.housing.costs",
"Youth.unemployment..18.24.receiving.JSA.or.Universal.Credit.","Unemployment.benefit..JSA.and.Universal.Credit.",
"Children..dependent.children.aged.under.20..in.families.in.receipt.of.IS.JSA.or.whose.income.is..60..of.median.income"
)
# List of renamed variables
col_names_rename = c("LSOA.Code","NOx","PM10","PM2.5",
"Pop.aged.0.15","Pop.aged.65.","Pop.density",
"Change.pop","Christian","No.rel.belief","Muslim",
"White.ethnic","Black.ethnic","Asian.ethnic","Born.in.EU.Acc",
"Born.non.Euro","Main.lang.Eng","Econ.inactive",
"No.qualifications","IMD",
"Households.pov","Net.household.inc",
"Youth.unemploy","Unemployment.benefit",
"Children_und_20"
)
# Select relevant columns from master pollution
pollution_filtered = pollution[,col_names_filter]
# Assign renamed variable names
names(pollution_filtered) = col_names_rename
# Normalise and calculate euclidian distance between NOx and IMD/Household poverty
pollution_dist = pollution_filtered  %>%
select(LSOA.Code, NOx, IMD, Households.pov) %>%
mutate(sc_nox = scale(NOx), sc_imd = scale(IMD), sc_pov = scale(Households.pov)) %>%
mutate(dist_imd = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_imd) - pollution_dist$sc_imd)^2)) %>%
mutate(dist_pov = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_pov) - pollution_dist$sc_pov)^2)) %>%
# Standardise range for each index variable between 0 and 1
mutate(dist_imd_01 = pollution_dist$dist_imd/max(pollution_dist$dist_imd)) %>%
mutate(dist_pov_01 = pollution_dist$dist_pov/max(pollution_dist$dist_pov))
# Normalise and calculate euclidian distance between NOx and IMD/Household poverty
pollution_dist = pollution_filtered  %>%
select(LSOA.Code, NOx, IMD, Households.pov) %>%
mutate(sc_nox = scale(NOx), sc_imd = scale(IMD), sc_pov = scale(Households.pov))
test = pollution_dist %>%
mutate(dist_imd = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_imd) - pollution_dist$sc_imd)^2)) %>%
mutate(dist_pov = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_pov) - pollution_dist$sc_pov)^2)) %>%
# Standardise range for each index variable between 0 and 1
mutate(dist_imd_01 = pollution_dist$dist_imd/max(pollution_dist$dist_imd)) %>%
mutate(dist_pov_01 = pollution_dist$dist_pov/max(pollution_dist$dist_pov))
rm(pollution_dist)
# Normalise and calculate euclidian distance between NOx and IMD/Household poverty
pollution_dist = pollution_filtered  %>%
select(LSOA.Code, NOx, IMD, Households.pov) %>%
mutate(sc_nox = scale(NOx), sc_imd = scale(IMD), sc_pov = scale(Households.pov)) %>%
# pollution_dist = pollution_dist %>%
mutate(dist_imd = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_imd) - pollution_dist$sc_imd)^2)) %>%
mutate(dist_pov = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_pov) - pollution_dist$sc_pov)^2)) %>%
# Standardise range for each index variable between 0 and 1
mutate(dist_imd_01 = pollution_dist$dist_imd/max(pollution_dist$dist_imd)) %>%
mutate(dist_pov_01 = pollution_dist$dist_pov/max(pollution_dist$dist_pov))
pollution_dist = pollution_filtered  %>%
select(LSOA.Code, NOx, IMD, Households.pov) %>%
mutate(sc_nox = scale(NOx), sc_imd = scale(IMD), sc_pov = scale(Households.pov)) %>%
# pollution_dist = pollution_dist %>%
mutate(dist_imd = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_imd) - pollution_dist$sc_imd)^2)) %>%
mutate(dist_pov = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_pov) - pollution_dist$sc_pov)^2))
# Normalise and calculate euclidian distance between NOx and IMD/Household poverty
pollution_dist = pollution_filtered  %>%
select(LSOA.Code, NOx, IMD, Households.pov) %>%
mutate(sc_nox = scale(NOx), sc_imd = scale(IMD), sc_pov = scale(Households.pov))
pollution_dist = pollution_dist %>%
mutate(dist_imd = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_imd) - pollution_dist$sc_imd)^2)) %>%
mutate(dist_pov = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_pov) - pollution_dist$sc_pov)^2))
# Standardise range for each index variable between 0 and 1
pollution_dist = pollution_dist %>%
mutate(dist_imd_01 = pollution_dist$dist_imd/max(pollution_dist$dist_imd)) %>%
mutate(dist_pov_01 = pollution_dist$dist_pov/max(pollution_dist$dist_pov))
View(pollution_dist)
rm(pollution_dist)
# Normalise and
pollution_dist = pollution_filtered  %>%
select(LSOA.Code, NOx, IMD, Households.pov) %>%
mutate(sc_nox = scale(NOx), sc_imd = scale(IMD), sc_pov = scale(Households.pov))
# Compute euclidian distance between NOx and IMD/Household poverty
pollution_dist = pollution_dist %>%
mutate(dist_imd = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_imd) - pollution_dist$sc_imd)^2)) %>%
mutate(dist_pov = sqrt((min(pollution_dist$sc_nox) - pollution_dist$sc_nox)^2 +
(min(pollution_dist$sc_pov) - pollution_dist$sc_pov)^2))
# Standardise range for each index variable between 0 and 1
pollution_dist = pollution_dist %>%
mutate(dist_imd_01 = pollution_dist$dist_imd/max(pollution_dist$dist_imd)) %>%
mutate(dist_pov_01 = pollution_dist$dist_pov/max(pollution_dist$dist_pov))
